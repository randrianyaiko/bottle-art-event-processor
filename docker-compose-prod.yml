version: '3.8'

services:
  kafka:
    image: confluentinc/cp-kafka:7.8.3
    container_name: kafka
    ports:
      - "9094:9094"
      - "9093:9093"
    environment:
      # Limit JVM heap to reduce memory usage
      KAFKA_HEAP_OPTS: "-Xms128M -Xmx128M"
      KAFKA_KRAFT_MODE: 'true'
      CLUSTER_ID: '1L6g7nGhU-eAKfL--X25wo'
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

      # Listeners
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://${EC2_IP}:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Data storage
      KAFKA_LOG_DIRS: /var/lib/kafka/data

    volumes:
      - kafka_kraft:/var/lib/kafka/data

    networks:
      ecommerce_net:
        aliases:
          - kafka

    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server=localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 10

    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  redis:
    image: redis:8.2
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 128mb --maxmemory-policy allkeys-lru
    container_name: redis
    restart: unless-stopped
    networks:
      ecommerce_net:
        aliases:
          - redis
    volumes:
      - redis_data:/data
    mem_limit: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    ports:
      - "6379:6379"

  consumer:
    image: ${IMAGE_NAME}
    command: python app.py
    restart: unless-stopped
    networks:
      ecommerce_net:
        aliases:
          - consumer
    env_file:
      - .env
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_started
    environment:
      FASTEMBED_CACHE_DIR: /cache
      FASTEMBED_MODEL_NAME: ${FASTEMBED_MODEL_NAME}
    volumes:
      - fastembed_cache:/cache
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

volumes:
  kafka_data:
  redis_data:
  kafka_kraft:
  fastembed_cache:

networks:
  shared-net:
    driver: bridge
  ecommerce_net:
    driver: bridge
